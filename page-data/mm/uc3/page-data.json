{"componentChunkName":"component---src-pages-mm-uc-3-index-mdx","path":"/mm/uc3/","result":{"pageContext":{"frontmatter":{"title":"Use Case 3 - Dynamic Threshold","description":null},"relativePagePath":"/mm/uc3/index.mdx","titleType":"page","MdxNode":{"id":"3ee21884-2606-5bf2-b255-78f643b870a9","children":[],"parent":"1ab6d4bd-4d99-52c4-8898-9a010811a2a6","internal":{"content":"---\ntitle: Use Case 3 - Dynamic Threshold\ndescription: \n---\n\n### Dynamic Threshold.\n\n  In this lab, we are looking at the Dynamic Threshold capability of Metric Manager.  We will be looking at data extracted and sanitized from a customer.  The key here is the resource being monitored is still capable of handling the traffic.  In traditional monitoring, most likely, the threshold has not been breached, yet, due to abnormal behavior, Metric Manager allows a pro-active event to be generated.\n\n### The Customer.\n\n  This scenario occurred at a major telecommunications company in the US.\n\n### The User Case.\n\n  Metric Manager alerted a customer that there was much more traffic than usual on many of their network links. These links had sufficient capacity for this new traffic, so any other systems generated no static monitoring events. It was __a denial of service attack__ that they detected before any of their customers were affected.\n\n  Any customers with public-facing channels of any kind would typically be interested in this.\n  Denial-of-service type attacks are often not deliberate or malicious but result from misconfiguration, poor change management, or failures in a system.\n\n### The lab exercise.\n\n  Select the `Detected Anomalies` tab, or close your current tab from the previous use case.\n\n  <img src=\"./images/UC32.png\" alt=\"Watson AIOps Metric Manager\" width=\"900\" align=\"center\"/>\n\n  Select the `Intotalbytes is Higher than expected. Actual 3.768e7 Expected: 1.815e7` for `GigabitLink-c0372` Node.\n\n  Observe:\n\n  - The metric affected is `Intotalbytes`. It's more than twice its normal value than is usual at this time of day. \n  - We can clearly see the resource being impacted – `GigabitLink-c0372`. This data comes from a customer, and this is a __production__ link the customer care a lot.\n\n  Right-click and choose \"ServiceDiagnosis...\" to launch and do further investigation on the chart.\n\n  <img src=\"./images/UC33.png\" alt=\"Watson AIOps Metric Manager\" width=\"900\" align=\"center\"/>\n\n  Observe:\n\n  - The behavior of InTotalBytes for the last weeks can be seen.\n  - The green area is the baseline that indicates the expected range of values. \n  - The red zone at the right of the chart shows where something unexpected has happened\n\n  We can take a closer look at the area of interest by zooming. Click on the chart where we want to start the zoom and drag to cover just past the red area. You always should include some of the chart's \"normal\" values so you can compare.\n\n  <img src=\"./images/UC34.png\" alt=\"Watson AIOps Metric Manager\" width=\"900\" align=\"center\"/>\n\n  Observe:\n\n  - Typically, metrics have shifting behavior and short-lived natural spikes. The same metric may have very different expected values on different resources. This leads to a one-size-fits-all for static thresholds – too tight, and there are many events, which end up being ignored. Too loose, and problems are not found until users are impacted. \n  - In this case, the link in question can handle this throughput without a problem but will have a problem later if it keeps growing. \n  - If it stops growing, the system is still showing far more capacity usage than it's really using, potentially leading to wastefulness and unnecessary upgrades.\n\n### Customer Value.\n\n  - Dynamic thresholds and eventing on every metric in your system without any configuration.\n  - Early detection of emerging problems so that action can be taken before the users are impacted.\n  - Single place where every metric from every data source can be visualised together with its normal behavior.\n\n### Customer Quotes.\n\n  - \"_IBM was able to detect 100% of the major incidents that occurred, including silent failures and predicting outages where possible; showing an annual saving of ~300k and product payback period of 5 months._\"\n\n","type":"Mdx","contentDigest":"3e472afe829d73f4e6abc350857e3af2","counter":153,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Use Case 3 - Dynamic Threshold","description":null},"exports":{},"rawBody":"---\ntitle: Use Case 3 - Dynamic Threshold\ndescription: \n---\n\n### Dynamic Threshold.\n\n  In this lab, we are looking at the Dynamic Threshold capability of Metric Manager.  We will be looking at data extracted and sanitized from a customer.  The key here is the resource being monitored is still capable of handling the traffic.  In traditional monitoring, most likely, the threshold has not been breached, yet, due to abnormal behavior, Metric Manager allows a pro-active event to be generated.\n\n### The Customer.\n\n  This scenario occurred at a major telecommunications company in the US.\n\n### The User Case.\n\n  Metric Manager alerted a customer that there was much more traffic than usual on many of their network links. These links had sufficient capacity for this new traffic, so any other systems generated no static monitoring events. It was __a denial of service attack__ that they detected before any of their customers were affected.\n\n  Any customers with public-facing channels of any kind would typically be interested in this.\n  Denial-of-service type attacks are often not deliberate or malicious but result from misconfiguration, poor change management, or failures in a system.\n\n### The lab exercise.\n\n  Select the `Detected Anomalies` tab, or close your current tab from the previous use case.\n\n  <img src=\"./images/UC32.png\" alt=\"Watson AIOps Metric Manager\" width=\"900\" align=\"center\"/>\n\n  Select the `Intotalbytes is Higher than expected. Actual 3.768e7 Expected: 1.815e7` for `GigabitLink-c0372` Node.\n\n  Observe:\n\n  - The metric affected is `Intotalbytes`. It's more than twice its normal value than is usual at this time of day. \n  - We can clearly see the resource being impacted – `GigabitLink-c0372`. This data comes from a customer, and this is a __production__ link the customer care a lot.\n\n  Right-click and choose \"ServiceDiagnosis...\" to launch and do further investigation on the chart.\n\n  <img src=\"./images/UC33.png\" alt=\"Watson AIOps Metric Manager\" width=\"900\" align=\"center\"/>\n\n  Observe:\n\n  - The behavior of InTotalBytes for the last weeks can be seen.\n  - The green area is the baseline that indicates the expected range of values. \n  - The red zone at the right of the chart shows where something unexpected has happened\n\n  We can take a closer look at the area of interest by zooming. Click on the chart where we want to start the zoom and drag to cover just past the red area. You always should include some of the chart's \"normal\" values so you can compare.\n\n  <img src=\"./images/UC34.png\" alt=\"Watson AIOps Metric Manager\" width=\"900\" align=\"center\"/>\n\n  Observe:\n\n  - Typically, metrics have shifting behavior and short-lived natural spikes. The same metric may have very different expected values on different resources. This leads to a one-size-fits-all for static thresholds – too tight, and there are many events, which end up being ignored. Too loose, and problems are not found until users are impacted. \n  - In this case, the link in question can handle this throughput without a problem but will have a problem later if it keeps growing. \n  - If it stops growing, the system is still showing far more capacity usage than it's really using, potentially leading to wastefulness and unnecessary upgrades.\n\n### Customer Value.\n\n  - Dynamic thresholds and eventing on every metric in your system without any configuration.\n  - Early detection of emerging problems so that action can be taken before the users are impacted.\n  - Single place where every metric from every data source can be visualised together with its normal behavior.\n\n### Customer Quotes.\n\n  - \"_IBM was able to detect 100% of the major incidents that occurred, including silent failures and predicting outages where possible; showing an annual saving of ~300k and product payback period of 5 months._\"\n\n","fileAbsolutePath":"/Users/dymaczew/Documents/_code/aiops/think-cp4wa-lab/src/pages/mm/uc3/index.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}